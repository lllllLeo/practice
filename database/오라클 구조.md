오라클 구조
===
# 1. I/O와 디스크의 관계
# 2. 오라클의 여러 프로세스
# 3. 캐시와 공유 메모리
# 4. SQL문 분석과 공유 풀 
프로그래밍 언어와 SQL문의 가장 큰 차이는 SQL문은 '처리 방법(절차)'을 기술하지 않는다.  
`SELECT A FROM B WHERE C = 1` 을 보면 어디에도 '인덱스를 사용해서'나 '풀 스캔을 해라'와 같은 처리 방법을 기술하지 않았다. 하지만 RDBMS에서는 **옵티마이저(파서)**가 SQL문을 분석하고 '실행 계획(plan)'이라고 하는 처리 방법을 생성해 준다.

### 오라클에서의 `분석`이란?
 - SQL문을 분석하고 어떤 요소(테이블이나 컬럼 등)로 구성되어 있는지를 조사하고 어떤 식으로 처리할지까지 알고리즘에 기반을 둔 처리하는 것을 가리킴.  

### 분석에 사용되는 오라클의 알고리즘  
- ~~`규칙 기반(rule base)`~~ : 오라클 10g부터 규칙 기반을 지원하지 않음.  
- `비용 기반(cost base)` : '처리 시간이나 I/O 횟수가 가장 작다고 생각되는 처리 방법이 최상이다'라는 알고리즘

오라클에서는 처리 시간이나 I/O 횟수를 예측하기 위해서 '비용'이라고 불리는 수치를 이용한다. 

`비용` : 처리에 필요하다고 생각되는 시간 또는 사용량  
  - '통계 정보'라 불리는 기초 수치를 기반으로 계산    
  
`통계 정보` : 비용을 계산하기 위한 기초적인 정보들이 들어있음. (이 테이블에는 데이터가 몇 건이나 존재하며, 데이터양은 어느 정도이고, 컬럼의 최댓값, 최솟값은 어떠며 이 테이블의 인덱스는 ~'와 같은 테이블이나 인덱스에 관한 기초 수치.  
  - 오라클에서는 `통계 정보`를 '통계 수집(dbms_stats)'이라고 불리는 작업을 통해 얻을 수 있다.(오라클 10g부터 오라클이 자동으로 수행)
---
## 공유풀의 동작과 구조
## 공유풀 
- SQL문을 분석하는데 드는 CPU 자원이 소모되기 때문에 이미 사용한 실행계획을 재사용하기 위함
- 공유 풀은 실행 계획을 재이용하고 분석 작업을 줄이기 위한 존재 -> 잘 이용하면 CPU자원 절약
- 프로세스 간에 공유하지 않으면 안 되기 때문에 버퍼 캐시와 마찬가지로 **공유 메모리**에 존재함
  - 대부분 공유 메모리에 버퍼 캐시가 많이 차지하고 남은 일부가 공유 풀로 사용된다. 공유 풀은 **라이브러리 캐시, 딕셔너리 캐시**로 나눠진다.
    - 라이브러리 캐시 (Library Cache)  
    공유 풀의 중요한 역할인 **실행 계획** 등이 존재하며 SQL 정보의 캐시는 여기에서 수행한다.
    - 딕셔너리 캐시 (Dictionary Cache)  
    통계 정보의 캐시 등 주로 SQL의 실행에 필요한 메타 정보를 보관하고 있다.

## 동일한 SQL문 판단 기준
- 오라클은 해시 알고리즘을 사용해서 SQL문마다 ID를 생성
- 해시 함수에서는 대/소문자 구분한다.
  >SELECT id, email FROM user WHERE id = 1;  
  >Select id, email FROM user WHERE id = 2;  
  -> 대/소문자 다름. 서로 다른 SQL문으로 인식
- 검색 조건의 값이 다른 SQL문은 바인드 변수를 사용하면 같은 SQL문으로 판단
  - `바인드 변수` : 프로그램의 변수를 SQL문에서 사용하는 기능
  >SELECT id, email FROM user WHERE id = :A;  
  >SELECT id, email FROM user WHERE id = :A;  
  ->:A라는 변수에 값 1,2를 넣고 실행을 하면 둘은 같은 작업을 수행한다. 즉 같은 SQL문이라고 인식하기 때문에 캐시에 남아있으면 분석 작업을 수행하지 않는다.

## 분석(Parse)
- 하드 파스(hard parse)
  - 공유 풀에 실행 계획이 없으므로 실행 계획을 생성하는 경우
- 소프트 파스(soft parse)
  - 공유 풀에 캐시되어 있는 실행계획이 존재하므로 재이용하는 경우

## 요약
- SQL문에는 처리 방법이 적혀 있지 않기 때문에 오라클이 처리 방법(실행 계획)을 생성할 필요가 있다.
- 실행 계획의 좋고 나쁨에 따라 성능이 크게 변한다
- 실행 계획을 생성하기 위해서는 많은 양의 CPU를 사용하기 때문에 공유 풀(라이브러리 캐시)에 실행 계획을 캐시해서 재활용한다.


# 5. 오라클의 기동과 정지
(Windows용과 UNIX용 오라클의 내부 구조는 동일하지만 Windows용 오라클은 멀티스레드 구조, UNIX용 오라클은 멀티프로세스 구조이다. 아래 설명은 UNIX용 환경임)

## 오라클 기동 4가지 상태
- OPEN
  - 데이터 처리를 할 수 있는 상태.
  - SQL을 처리할 수 있는 상태
- MOUNT
  - 데이터 파일 등에 접근할 수 있는 상태 (컨트롤 파일을 읽은 상태)
- NOMOUNT
  - 백그라운드 프로세스와 공유 메모리가 존재하는 상태
- SHUTDOWN
  - 정지상태  

### 수행하는 작업  
`SHUTDOWN -> NOMOUNT -> MOUNT -> OPEN `  
>          1          2        3    

1. 파라미터를 읽어 와서 백그라운드 프로세스를 기동시키고 공유 메모리를 할당한다.
1. 컨트롤 파일을 읽어 온다.
1. 데이터 파일에 대한 체크 등을 한다.

- 컨트롤 파일 : 데이터베이스의 구성 정보가 적혀 있는 파일(데이터베이스의 파일(데이터 파일이나 redo log 파일) 경로 등)을 알 수 있다.  
- 데이터 파일 : 데이터가 보관된 파일
- redo log 파일 : 데이터의 변경 이력을 보관하는 파일  

### 인스턴스 (instance)
 - 오라클에서는 관리하기 위한 단위로 '인스턴스'라는 용어를 사용 -> **데이터베이스를 관리하는 것**
 - **'백그라운드 프로세스 + 공유 메모리'**
 - 'NOMOUNT' 상태가 인스턴스가 기동한 상태

 ## 기동 처리의 흐름
 1. 기동 정지 상태에서 NOMOUNT로 전환  
 sqlplus에 관리자 계정으로 접속 후 
 > \> startup nomount  

-> 정지 상태에서 'NOMOUNT'상태로 변경한다. 이 명령어는 내부적으로 환경 변수 ORACLE_HOME과 ORACLE_SID를 토대로 초기화 파라미터 파일을 찾아서 읽는다. 읽어 온 파라미터를 토대로 공유 메모리를 확보하고 백그라운드 프로세스를 생성한다.

2. NOMOUNT로부터 MOUNT로 전환  

> \> alter database mount

-> 초기화 파라미터에 기술된 컨트롤 파일의 경로를 사용해 컨트롤 파일을 열어 내용을 읽어 온다. -> redo log 파일이나 데이터 파일의 위치를 파악할 수 있음. 이때, 위치를 알아내는 것 뿐이므로 파일이 없다고 해도 이 시점에서는 에러가 발생하지 않는다.

3. MOUNT에서 OPEN으로 전환

> \> alter database open

-> 명령어 내부에서는 데이터 파일을 열어서 간단한 점검 (오라클이 내부적으로 사용하는 데이터들의 앞뒤가 맞는 상황인지 등)을 하거나, 백그라운드 프로세스를 기동함. 마무리가 완료되면 데이터 파일을 읽고 기록할 수 있는 상태.   
즉, OPEN 상태가 된다.(SQL을 실행할 수 있는 상태)

위는 기동을 자세하게 보여주기 위해 3단계로 명령어를 작성하였지만  

정지 상태에서
> \> startup  

을 입력하면 위와 같이 세 가지의 명령어를 수행하고 OPEN 상태가 된다.

## 기동 종료
> \> shutdown
- 접속한 모든 오라클 클아이언트의 접속이 종료한 후에 기동 작업의 역순으로 데이터베이스를 단은 후에 인스턴스를 종료한다.  
- **인스턴스의 정지**란 공유 메모리를 반환하고 백그라운드 프로세스를 정지하는 것이다.
- 기동 종료시 추가 작업  
  - 버퍼 캐시에 분산된 데이터를 정리하는 것
  - 성능상의 이유로 변경된 데이터를 즉시 데이터 파일에 보관하지 않는다. 기록하지 않은 변경된 데이터를 데이터베이스를 닫는 작업의 일환으로 데이터 파일에 기록하는 것이 이 작업이다.  

### 인스턴스 복구(instance recovery)
- 기동이 종료되고 변경된 데이터를 기록하지 않고 종료하면 다음 기동 시에 데이터를 복구함. (오라클이 알아서 수행)
- 데이터 파일에 기록되지 않은 데이터는 redo log 파일의 데이터를 사용해서 복구 (오래된 데이터 파일의 내용 -> 최신 데이터 파일의 내용으로 교체)
- 






